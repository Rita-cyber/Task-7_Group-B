# -*- coding: utf-8 -*-
"""Task 7 Group B

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ikKgNZiJlF3CvmcjAAOIaFAxj5BFs2yR
"""

#!/usr/bin/env python
# coding: utf-8

# In[1]:

!pip install pylint
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from pylint.lint import Run
import string
import re
import pandas as pd
import nltk

nltk.download("stopwords")

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/My Drive/Database 2/Result3.csv')
df.head()

#sorting df by productid

df.sort_values(["ProductId"], axis=0, ascending=True, inplace=True)

df

#we want to know how many positive and negative reviews we have
#we import the first sql table we created

FILTER = pd.read_csv('/content/drive/My Drive/Database 2/Result2.csv')

FILTER.head()

#we add a column which displays which is positive and negative
FILTER["Result"] = FILTER["Score"].apply(lambda score: "positive" if score > 3 else "negative")
FILTER.head(5)

#total negative and positive reviews
CONN = FILTER["Result"].value_counts()

CONN

#Remove HTML tags
TAG_RE = re.compile(r'<[^>]+>$[...] ')

def remove_tags(text):
    return TAG_RE.sub('', text)

df['Text']=df["Text"].apply(remove_tags)

df

def remove_punctuations(text):
    for punctuation in string.punctuation:
        text = text.replace(punctuation, '')
    return text

df["Text"] = df['Text'].apply(remove_punctuations)

df

df['Non Alphanumeric'] = df['Text'].str.count(r'[^a-zA-Z0-9 ]')

df

# In[9]:


#check to see if the length of the word is greater than 2

df.dropna(inplace=True)


df['Text_len'] = df['Text'].astype(str).str.len()

df

#convert words to lower case

LOWER = df['Text'].str.lower()
LOWER.head()

#now we have to remove stopwords

df['Text'] = df['Text'].str.lower().str.split() 

STOP = stopwords.words('english')
df['Text'] = df['Text'].apply(lambda x: [item for item in x if item not in STOP])

ENGLISH_STEMMER = SnowballStemmer('english', ignore_stopwords=True)
df['stemmed'] = df['Text'].apply(lambda x: [ENGLISH_STEMMER.stem(y) for y in x])

df.head()